{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 100, 100, 3) arharva.npy\n",
      "(20, 100, 100, 3) yash.npy\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    " \n",
    "d = {}\n",
    "cnt = 0\n",
    "for f in os.listdir(): # scan the current directory for files\n",
    "    if f.endswith(\".npy\"): # only take .npy files\n",
    "        imgs = np.load(f)  # load images as np array \n",
    "        print(imgs.shape,f) # display the shape of image array\n",
    "        X.append(imgs) # append image to list\n",
    "        labels = np.ones((imgs.shape[0]))*cnt # adding 0 and 1 as last column\n",
    "        Y.append(labels) # adding labels\n",
    "        d[cnt] = f[:-4] # only name, extension removed\n",
    "        cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 100, 100, 3) (40,)\n",
      "{0: 'arharva', 1: 'yash'}\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X = X.reshape((40,100,100,3)) \n",
    "Y = Y.reshape((40,))\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the classifier to match and classify iamges\n",
    "detector = cv2.CascadeClassifier(\"Datasets/FaceCascade/templatedata.xml\")\n",
    "\n",
    "# get control of 0th camera attached to pc\n",
    "camera = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(p1,p2):\n",
    "    return np.sum((p1-p2)**2)**0.5\n",
    "\n",
    "def KNN(X,Y,test_point, K=5):\n",
    "    d = [] # will store distance \n",
    "    m = X.shape[0] # 100,2 -> total number of points\n",
    "    \n",
    "    #Step1 - find distance of testpoint from all points\n",
    "    for i in range(0,m):\n",
    "        current_dist = dist(test_point, X[i]) # find distance of testpoint from current point\n",
    "        d.append((current_dist,Y[i])) # append distance along with pair into d\n",
    "    \n",
    "    #Step2 - sort all points according to distances\n",
    "    d = sorted(d) # by default based on the first key of tupple\n",
    "    \n",
    "    #Step3 - Pick the first k points\n",
    "    d = d[:K] # pick only the first k elements, can be varied\n",
    "    \n",
    "    #Step4 - Create a numpy array\n",
    "    d = np.array(d) \n",
    "    d = d[:,1] # get all rows, but elements from only first column\n",
    "    \n",
    "    #Step5 - Find out unique classes and counts\n",
    "    uniq, cnts = np.unique(d,return_counts=True) # uniq denotes (0 and 1) and cnts is array of individual instances \n",
    "    idx = np.argmax(cnts) # get the index of maximum element. the cnts variable contains two elements. one is zero and other is one. on the zeroth element, there are instances of one. on one it contains instances of one.\n",
    "    \n",
    "    #Step6 - Find the label with maximum count\n",
    "    pred = uniq[idx] # now pred has 0 or 1 whichever is maximum\n",
    "    \n",
    "    #Step7 - Map and send data \n",
    "    return int(pred) # replace 0 or 1 with respective mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start an infinite loop to get all images\n",
    "while True:\n",
    "    # start capturing frames\n",
    "    b,img = camera.read()\n",
    "    \n",
    "    # if no image captured, skip loop\n",
    "    if b==False:\n",
    "        continue\n",
    "    \n",
    "    # after every round of checks, scale 1.5 times\n",
    "    faces = detector.detectMultiScale(img, 1.5)\n",
    "\n",
    "    # if no faces detected in frame, skip loop execution\n",
    "    if(len(faces)==0):\n",
    "        continue\n",
    "        \n",
    "    # iterate for face in faces\n",
    "    for f in faces:\n",
    "        f = faces[0] # get the first or most significant face\n",
    "        x,y,w,h = f # capture x coordinate, y coordinate, width and height from f\n",
    "        green = (0,255,0) # define color for box as green\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), green, 5 )  # draw rectangle around faced  \n",
    "        crop_face = img[y:y+h,x:x+w] # get reduced image of face fro photo\n",
    "        small_face = cv2.resize(crop_face,(100,100)) # resize the small_face to avoid misfits\n",
    "        \n",
    "        predicted_name = d[KNN(X,Y,small_face)] # predict names of people\n",
    "        \n",
    "        cv2.putText(img,predicted_name,(x, y-20),cv2.FONT_HERSHEY_SIMPLEX, 1.0,(255,255,255)) # write names of people on image\n",
    "        \n",
    "    cv2.imshow(\"Image\", img) # feed outwards\n",
    "      \n",
    "    # tackle exit using q\n",
    "    key = cv2.waitKey(1)&0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "    # wait 1 millisecond before next frame\n",
    "    cv2.waitKey(1) \n",
    "    \n",
    "# release control of camera\n",
    "camera.release()\n",
    "# destroy all window under operations\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
